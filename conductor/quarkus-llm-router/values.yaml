labels:
  app: quarkus-llm-router
  app.kubernetes.io/component: quarkus-llm-router
  app.kubernetes.io/instance: quarkus-llm-router
  app.kubernetes.io/name: quarkus-llm-router
  app.kubernetes.io/part-of: chatbot-application

name: quarkus-llm-router

image:  quay.io/redhat-composer-ai/conductor@sha256:1103ce5e8c7a0b1335817e4600a1e829660aec9b9d428d093193d06f97e01662
imagePullPolicy: Always

# Quarkus profile
profile: prod

serviceMesh:
  enabled: false

# Default secret is created by the mongodb chart
mongodb:
  host: mongodb://mongo-test-mongodb.svc:27017/
  authSource: admin
  username: root
  passwordSecret: mongodb-{{ .Release.Namespace }}
  passwordKey: mongodb-root-password

openAIRuntime:
  url: https://vllm-predictor-{{ .Release.Namespace }}.{{ .Values.clusterDomain }}/v1
  apikey: abc123
  modelname: vllm

route:
  # The timeout needs to be pretty high if there are no GPUs available
  timeout: 200s

# Uncomment the following to set log level to DEBUG
# logLevel: DEBUG

resources:
  limits:
    cpu: '2'
    memory: 4Gi
  requests:
    cpu: 500m
    memory: 1Gi
    
tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Equal
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Equal
    value: "True"
